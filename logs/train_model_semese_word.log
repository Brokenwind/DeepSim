nohup: ignoring input
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
INFO:starting loading embedding
INFO:loading Word2Vec object from ../model/char2vec_gensim256
DEBUG:{'uri': '../model/char2vec_gensim256', 'kw': {}, 'mode': 'rb'}
INFO:loading wv recursively from ../model/char2vec_gensim256.wv.* with mmap=None
INFO:setting ignored attribute vectors_norm to None
INFO:loading vocabulary recursively from ../model/char2vec_gensim256.vocabulary.* with mmap=None
INFO:loading trainables recursively from ../model/char2vec_gensim256.trainables.* with mmap=None
INFO:setting ignored attribute cum_table to None
INFO:loaded ../model/char2vec_gensim256
INFO:loading Word2Vec object from ../model/word2vec_gensim256
DEBUG:{'uri': '../model/word2vec_gensim256', 'kw': {}, 'mode': 'rb'}
INFO:loading wv recursively from ../model/word2vec_gensim256.wv.* with mmap=None
INFO:loading vectors from ../model/word2vec_gensim256.wv.vectors.npy with mmap=None
INFO:setting ignored attribute vectors_norm to None
INFO:loading vocabulary recursively from ../model/word2vec_gensim256.vocabulary.* with mmap=None
INFO:loading trainables recursively from ../model/word2vec_gensim256.trainables.* with mmap=None
INFO:loading syn1neg from ../model/word2vec_gensim256.trainables.syn1neg.npy with mmap=None
INFO:setting ignored attribute cum_table to None
INFO:loaded ../model/word2vec_gensim256
INFO:end loading embedding
2019-03-03 10:19:54.672331: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-03 10:19:54.776938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-03-03 10:19:54.777366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
totalMemory: 11.17GiB freeMemory: 11.09GiB
2019-03-03 10:19:54.777393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-03 10:19:55.100395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-03 10:19:55.100449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-03 10:19:55.100459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-03 10:19:55.100734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10742 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
2019-03-03 10:19:55.679233: W tensorflow/core/framework/allocator.cc:122] Allocation of 494334976 exceeds 10% of system memory.
2019-03-03 10:19:56.042482: W tensorflow/core/framework/allocator.cc:122] Allocation of 494334976 exceeds 10% of system memory.
2019-03-03 10:20:07.904815: W tensorflow/core/framework/allocator.cc:122] Allocation of 494334976 exceeds 10% of system memory.
2019-03-03 10:20:08.276104: W tensorflow/core/framework/allocator.cc:122] Allocation of 494334976 exceeds 10% of system memory.
Building prefix dict from the default dictionary ...
DEBUG:Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
DEBUG:Dumping model to file cache /tmp/jieba.cache
Loading model cost 1.188 seconds.
DEBUG:Loading model cost 1.188 seconds.
Prefix dict has been built succesfully.
DEBUG:Prefix dict has been built succesfully.
INFO:length of featured sentence is 102477
2019-03-03 10:20:28.462805: W tensorflow/core/framework/allocator.cc:122] Allocation of 494334976 exceeds 10% of system memory.
=======   CONFIG:  ('siamese', 'word', 20, 'gensim', 256, [100, 80, 64, 64], 116, 8)
=======   CONFIG:  ('siamese', 'word', 20, 'gensim', 256, [100, 80, 64, 64], 116, 8)
total iters per cycle(epoch): 1562
Train on 99915 samples, validate on 2562 samples
Epoch 1/116
 - 371s - loss: 19.8200 - binary_crossentropy: 0.6703 - acc: 0.8137 - val_loss: 0.7573 - val_binary_crossentropy: 0.5078 - val_acc: 0.7923
Epoch 2/116
 - 367s - loss: 1.6335 - binary_crossentropy: 0.6291 - acc: 0.8170 - val_loss: 0.7075 - val_binary_crossentropy: 0.5183 - val_acc: 0.8029
Epoch 3/116
 - 367s - loss: 1.5798 - binary_crossentropy: 0.6245 - acc: 0.8170 - val_loss: 0.6795 - val_binary_crossentropy: 0.5138 - val_acc: 0.8056
Epoch 4/116
 - 367s - loss: 1.5139 - binary_crossentropy: 0.6124 - acc: 0.8173 - val_loss: 0.6484 - val_binary_crossentropy: 0.4956 - val_acc: 0.8119
Epoch 5/116
 - 365s - loss: 1.5021 - binary_crossentropy: 0.6106 - acc: 0.8174 - val_loss: 0.6635 - val_binary_crossentropy: 0.5065 - val_acc: 0.8107
Epoch 6/116
 - 367s - loss: 1.4992 - binary_crossentropy: 0.6058 - acc: 0.8176 - val_loss: 0.6576 - val_binary_crossentropy: 0.5049 - val_acc: 0.8068
Epoch 7/116
 - 367s - loss: 1.4872 - binary_crossentropy: 0.6027 - acc: 0.8176 - val_loss: 0.6551 - val_binary_crossentropy: 0.5065 - val_acc: 0.8119
Epoch 8/116
 - 367s - loss: 1.4696 - binary_crossentropy: 0.5983 - acc: 0.8177 - val_loss: 0.6354 - val_binary_crossentropy: 0.4916 - val_acc: 0.8119
Epoch 9/116
 - 367s - loss: 1.4561 - binary_crossentropy: 0.5929 - acc: 0.8177 - val_loss: 0.6335 - val_binary_crossentropy: 0.4891 - val_acc: 0.8162
Epoch 10/116
 - 367s - loss: 1.4411 - binary_crossentropy: 0.5889 - acc: 0.8177 - val_loss: 0.6283 - val_binary_crossentropy: 0.4856 - val_acc: 0.8123
Epoch 11/116
 - 367s - loss: 1.4629 - binary_crossentropy: 0.5877 - acc: 0.8177 - val_loss: 0.6450 - val_binary_crossentropy: 0.4932 - val_acc: 0.8158
Epoch 12/116
 - 366s - loss: 1.4587 - binary_crossentropy: 0.5862 - acc: 0.8177 - val_loss: 0.6331 - val_binary_crossentropy: 0.4890 - val_acc: 0.8154
Epoch 13/116
 - 367s - loss: 1.4417 - binary_crossentropy: 0.5817 - acc: 0.8177 - val_loss: 0.6280 - val_binary_crossentropy: 0.4815 - val_acc: 0.8123
Epoch 14/116
 - 367s - loss: 1.4218 - binary_crossentropy: 0.5770 - acc: 0.8177 - val_loss: 0.6253 - val_binary_crossentropy: 0.4824 - val_acc: 0.8150
Epoch 15/116
 - 367s - loss: 1.4167 - binary_crossentropy: 0.5748 - acc: 0.8177 - val_loss: 0.6274 - val_binary_crossentropy: 0.4832 - val_acc: 0.8173
Epoch 16/116
 - 367s - loss: 1.4162 - binary_crossentropy: 0.5729 - acc: 0.8177 - val_loss: 0.6406 - val_binary_crossentropy: 0.4980 - val_acc: 0.8173
Epoch 17/116
 - 367s - loss: 1.4012 - binary_crossentropy: 0.5714 - acc: 0.8177 - val_loss: 0.6292 - val_binary_crossentropy: 0.4888 - val_acc: 0.8162
Epoch 18/116
 - 366s - loss: 1.4018 - binary_crossentropy: 0.5694 - acc: 0.8177 - val_loss: 0.6380 - val_binary_crossentropy: 0.4928 - val_acc: 0.8177
Epoch 19/116
 - 366s - loss: 1.3926 - binary_crossentropy: 0.5667 - acc: 0.8177 - val_loss: 0.6204 - val_binary_crossentropy: 0.4806 - val_acc: 0.8173
/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:109: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 123583744 elements. This may consume a large amount of memory.
  num_elements)
timer stopping
